# Elements of Reinforcement Learning.

Beyond the agent and the enviroment, one can identify four main subelements od a reinforcement learning system:

* A Policy
* A Reward Signal
* A Value Function

and optionally, a model of the enviroment.

A *policy* defines the learning agent's way of behaving at a given time. In general, policies may be stochastic, specifying probabilities for each action. 

A *reward signal* defines the goal of a reinforcement learning problem. The agent's role objective is to maximize the total reward it receives over the long run. 

Whereas the reward signal indicates what is good in immediate sense, a *value function* specifies what is good in the long run. 

The fourth and final element of some reinforcement learning systems is a model od th eenviroemnt. This is something that mimics the behavior of the envirometn, or more generally, that allows inferences to be made about how the enviroment will behave.

# An Extended Example: Tic-Tac-Toe

Consider the familiar child’s game of tic-tac-toe. Two players take turns playing on a three-by-three board. One player plays Xs and the other Os until one player wins by placing three marks in a row, horizontally, vertically, or diagonally, as the X player has in the game shown to the right. If the board fills up with neither player getting three in a row, then the game is a draw.

Because a skilled player can play so as never to lose, let us assume that we are playing against an imperfect player, one whose play is sometimes incorrect and allows us to win. For the moment, in fact, let us consider draws and losses to be equally bad for us. 

How might we construct a player that will find the imperfections in its opponent’s play and learn to maximize its chances of winning?

